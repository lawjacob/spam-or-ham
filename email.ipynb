{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pyro-ppl spacy transformers\n",
    "! python -m spacy download en_core_web_sm\n",
    "! pip install torch==2.3.0\n",
    "! pip install torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loading\n",
    "data src: https://www.kaggle.com/datasets/venky73/spam-mails-dataset/data\n",
    "we only care about column: text and label_num(binary identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv('spam_ham_dataset.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleansing and conversion to tokens,\n",
    "A text can include \n",
    "1. Subject\n",
    "2. From|To|CC|BCC\n",
    "3. attachment (e.g., filenames like \"hplnol09.xls\")\n",
    "4. numbers/extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def clean_email(text):\n",
    "    # Remove email headers \n",
    "    text = re.sub(r\"Subject:\\s*[^\\n]+\\n\", \"\", text)\n",
    "    text = re.sub(r\"\\b(From|To|CC|BCC):\\s*[^\\n]+\\n\", \"\", text, flags=re.I)\n",
    "    \n",
    "    # Remove attachments \n",
    "    text = re.sub(r\"\\(?\\s*see attached file:\\s*[^)]+\\.\\w{3,4}\\s*\\)?\", \"\", text, flags=re.I)\n",
    "    \n",
    "    # Remove numbers, punctuation, and extra spaces\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip().lower()\n",
    "    \n",
    "    # Lemmatize with spaCy\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.lemma_.strip()]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"cleaned_text\"] = df[\"text\"].apply(clean_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering\n",
    "N-grams and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=2000,\n",
    "    ngram_range=(1, 3),  # Include unigrams, bigrams, trigrams\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X = tfidf.fit_transform(df[\"cleaned_text\"])\n",
    "y = df[\"label_num\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Logistic Regression with HMC\n",
    "Prior: Normal(0,1)\n",
    "Likelihood: Sigmoid(X @ coef + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer.mcmc import HMC, MCMC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train = torch.tensor(X_train.toarray(), dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test.toarray(), dtype=torch.float32)\n",
    "\n",
    "# Define Bayesian model\n",
    "def model(X, y=None):\n",
    "    coef = pyro.sample(\"coef\", dist.Normal(0, 1).expand([X.shape[1]]))\n",
    "    bias = pyro.sample(\"bias\", dist.Normal(0, 1))\n",
    "    logits = X @ coef + bias\n",
    "    p = torch.sigmoid(logits)\n",
    "    \n",
    "    with pyro.plate(\"data\", X.shape[0]):\n",
    "        obs = pyro.sample(\"obs\", dist.Bernoulli(p), obs=y)\n",
    "    return logits\n",
    "\n",
    "# Run HMC\n",
    "hmc_kernel = HMC(model, step_size=0.001, trajectory_length=1)\n",
    "mcmc = MCMC(hmc_kernel, num_samples=1000, warmup_steps=200)\n",
    "mcmc.run(X_train, y_train)\n",
    "\n",
    "# Get posterior samples\n",
    "posterior = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predication & accuracy testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict on test data\n",
    "with torch.no_grad():\n",
    "    logits_test = X_test @ posterior[\"coef\"].mean(dim=0) + posterior[\"bias\"].mean()\n",
    "    prob_spam = torch.sigmoid(logits_test).numpy()\n",
    "\n",
    "# Accuracy\n",
    "accuracy = (prob_spam.round() == y_test).mean()\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
